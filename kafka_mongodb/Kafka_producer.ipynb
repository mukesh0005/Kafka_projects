{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_key = 'E3XtedDNSTi4tSgxjSEGuQ'\n",
    "secret_key = 'L7L0xN1ROQwx_8nexbmAxnozooucvQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username' : 'thunder_fist_',\n",
    "'password' : 'Veera@reddit123'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'Batman/0.0.1',\n",
       " 'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzIyNzk0ODY3LjE5MjQ3MiwiaWF0IjoxNzIyNzA4NDY3LjE5MjQ3MiwianRpIjoiTGRMWnJXdVNJYkJYa0czbjJCOGxFRnREUko3M2t3IiwiY2lkIjoiRTNYdGVkRE5TVGk0dFNneGpTRUd1USIsImxpZCI6InQyXzEwMWh6YXptc3EiLCJhaWQiOiJ0Ml8xMDFoemF6bXNxIiwibGNhIjoxNzE1MzA2MjEwMjk4LCJzY3AiOiJlSnlLVnRKU2lnVUVBQURfX3dOekFTYyIsImZsbyI6OX0.jIkDkS2VK5smvFTib4uKVKA1DX6gUKCUApOzzD3vqd-s6Aa13wgKT3TdfLJ3YO3ew1GtJagHH_xHNaMNVuQ82Cur5nbIYpsIGpQzez-9iM_AljjrA_I5nE1SLwcSc1ZNpsGofv--hhZyY_W17LjRDdcsH6_VJgaQ9nVvXv8Abt2XWT67P8IpBkMhB7pE6XYI-98g7AYe2uhYQvE8mVFaBKpYfN1xoWe3nHWEVts5d6Ayhs1FFbYmhwUZbQCJdGeCTdtsCEfeE2j8Y76KuwdDiCxBJo6YTVoCU1jxlpZohsa1-sZ1Ja9VrPGkcdkBN9yEDbAerop4rRe5VbQ_WqIg_A'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth = requests.auth.HTTPBasicAuth(client_key,secret_key)\n",
    "headers = {'User-Agent':'Batman/0.0.1'}\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "TOKEN = res.json()['access_token']\n",
    "headers['Authorization'] = f'bearer {TOKEN}'\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'praw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpraw\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'praw'"
     ]
    }
   ],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=client_key,\n",
    "                     client_secret=secret_key,\n",
    "                     username='thunder_fist_',\n",
    "                     password='Veera@reddit123',\n",
    "                     user_agent='Batman/0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_api(res):\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "\n",
    "    data = res.json()\n",
    "    children = data['data']['children']\n",
    "\n",
    "    raw_data = []\n",
    "    for post in children:\n",
    "        post_data = post['data']\n",
    "        raw_data.append({\n",
    "            'title': post_data['title'],\n",
    "            'author': post_data['author'],\n",
    "            'score': post_data['score'],\n",
    "            'id': post_data['id'],\n",
    "            'created': datetime.utcfromtimestamp(post_data['created']).strftime('%Y-%m-%d %H:%M:%S UTC'),\n",
    "            'num_comments': post_data['num_comments']\n",
    "        })\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    raw_df = pd.DataFrame(raw_data)\n",
    "\n",
    "    def sub_com(id):\n",
    "    # Get a submission (post) by its ID\n",
    "        submission = reddit.submission(id=id)\n",
    "        top_level_comment_bodies = []  # List to store top-level comment bodies\n",
    "        sub_comment_bodies = []  # List to store sub-comment bodies\n",
    "\n",
    "        # Function to recursively process comments and retrieve their bodies\n",
    "        def process_comments(comments):\n",
    "            for comment in comments:\n",
    "                if isinstance(comment, praw.models.Comment):\n",
    "                    sub_comment_bodies.append(comment.body)  # Append sub-comment body to list\n",
    "                    process_comments(comment.replies)  # Recursively process sub-comments\n",
    "\n",
    "        # Iterate over top-level comments\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, praw.models.Comment):\n",
    "                top_level_comment_bodies.append(top_level_comment.body)  # Append top-level comment body to list\n",
    "                process_comments(top_level_comment.replies)  # Process sub-comments recursively\n",
    "\n",
    "        return top_level_comment_bodies, sub_comment_bodies\n",
    "\n",
    "    def comments_to_json(sub_com_id):\n",
    "        # Call the sub_com function to get the data\n",
    "        top_level_comments, sub_comments = sub_com(sub_com_id)\n",
    "\n",
    "        # Ensure that both lists have the same length\n",
    "        min_length = min(len(top_level_comments), len(sub_comments))\n",
    "        top_level_comments = top_level_comments[:min_length]\n",
    "        sub_comments = sub_comments[:min_length]\n",
    "\n",
    "        # Create a dictionary with the data\n",
    "        data = {\n",
    "            'sub_com_id': [sub_com_id] * min_length,\n",
    "            'main_comment': top_level_comments,\n",
    "            'reply': sub_comments\n",
    "        }\n",
    "        comments_df = pd.DataFrame(data)\n",
    "\n",
    "        # Convert DataFrame to JSON\n",
    "        json_data = comments_df.to_json(orient='records')\n",
    "\n",
    "        return json_data\n",
    "    \n",
    "    raw_df['comments'] =raw_df['id'].apply(comments_to_json)\n",
    "\n",
    "    return raw_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_api(subreddit='batman', headers=None):\n",
    "    # Define client key, secret key, and auth data\n",
    "\n",
    "    # Define default headers if not provided\n",
    "    if headers is None:\n",
    "        headers = {'User-Agent': 'Batman/0.0.1'}\n",
    "\n",
    "    res = requests.get(f'https://oauth.reddit.com/r/{subreddit}/hot', headers=headers)\n",
    "    data = res.json()\n",
    "    children = data['data']['children']\n",
    "\n",
    "    raw_data = []\n",
    "    for post in children:\n",
    "        post_data = post['data']\n",
    "        raw_data.append({\n",
    "            'title': post_data['title'],\n",
    "            'author': post_data['author'],\n",
    "            'score': post_data['score'],\n",
    "            'id': post_data['id'],\n",
    "            'created': datetime.utcfromtimestamp(post_data['created']).strftime('%Y-%m-%d %H:%M:%S UTC'),\n",
    "            'num_comments': post_data['num_comments']\n",
    "        })\n",
    "\n",
    "    raw_df = pd.DataFrame(raw_data)\n",
    "\n",
    "    reddit = praw.Reddit(client_id=client_key,\n",
    "                         client_secret=secret_key,\n",
    "                         username=auth_data['username'],\n",
    "                         password=auth_data['password'],\n",
    "                         user_agent='Batman/0.0.1')\n",
    "\n",
    "    def sub_com(id):\n",
    "        submission = reddit.submission(id=id)\n",
    "        top_level_comment_bodies = []  \n",
    "        sub_comment_bodies = []  \n",
    "\n",
    "        def process_comments(comments):\n",
    "            for comment in comments:\n",
    "                if isinstance(comment, praw.models.Comment):\n",
    "                    sub_comment_bodies.append(comment.body)  \n",
    "                    process_comments(comment.replies)  \n",
    "\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, praw.models.Comment):\n",
    "                top_level_comment_bodies.append(top_level_comment.body)  \n",
    "                process_comments(top_level_comment.replies)  \n",
    "\n",
    "        return top_level_comment_bodies, sub_comment_bodies\n",
    "\n",
    "    def comments_to_json(sub_com_id):\n",
    "        top_level_comments, sub_comments = sub_com(sub_com_id)\n",
    "\n",
    "        min_length = min(len(top_level_comments), len(sub_comments))\n",
    "        top_level_comments = top_level_comments[:min_length]\n",
    "        sub_comments = sub_comments[:min_length]\n",
    "\n",
    "        data = {\n",
    "            'sub_com_id': [sub_com_id] * min_length,\n",
    "            'main_comment': top_level_comments,\n",
    "            'reply': sub_comments\n",
    "        }\n",
    "        comments_df = pd.DataFrame(data)\n",
    "\n",
    "        json_data = comments_df.to_json(orient='records')\n",
    "\n",
    "        return json_data\n",
    "    \n",
    "    raw_df['comments'] = raw_df['id'].apply(comments_to_json)\n",
    "\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m batman_raw_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrap_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubreddit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m batman_raw_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m, in \u001b[0;36mscrap_api\u001b[1;34m(subreddit, headers)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[0;32m     14\u001b[0m     post_data \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m     raw_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m: post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m---> 20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mutcfromtimestamp(post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS UTC\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_comments\u001b[39m\u001b[38;5;124m'\u001b[39m: post_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_comments\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m     })\n\u001b[0;32m     24\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(raw_data)\n\u001b[0;32m     26\u001b[0m reddit \u001b[38;5;241m=\u001b[39m praw\u001b[38;5;241m.\u001b[39mReddit(client_id\u001b[38;5;241m=\u001b[39mclient_key,\n\u001b[0;32m     27\u001b[0m                      client_secret\u001b[38;5;241m=\u001b[39msecret_key,\n\u001b[0;32m     28\u001b[0m                      username\u001b[38;5;241m=\u001b[39mauth_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     29\u001b[0m                      password\u001b[38;5;241m=\u001b[39mauth_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     30\u001b[0m                      user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatman/0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "batman_raw_df = scrap_api(subreddit='batman',headers=headers)\n",
    "batman_raw_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
